# Iris Recognition con IrisCode

Progetto universitario di riconoscimento dellâ€™iride basato su una versione semplificata dellâ€™algoritmo di Daugman, sviluppato in Python.  
Lâ€™obiettivo Ã¨:

- estrarre lâ€™**IrisCode** da immagini dellâ€™occhio,
- calcolare le **distanze di Hamming** tra codici,
- analizzare le prestazioni del sistema tramite **istogrammi**, **ROC curve** e **metriche quantitative**.

---

## ğŸ“š Contenuti

- [Descrizione del progetto](#descrizione-del-progetto)
- [Algoritmo implementato](#algoritmo-implementato)
  - [1. Segmentazione dellâ€™iride](#1-segmentazione-delliride)
  - [2. Normalizzazione (Rubber Sheet Model)](#2-normalizzazione-rubber-sheet-model)
  - [3. Estrazione dellIrisCode](#3-estrazione-delliriscode)
  - [4. Distanza di Hamming e decisione](#4-distanza-di-hamming-e-decisione)
- [Struttura del dataset](#struttura-del-dataset)
- [Struttura del progetto](#struttura-del-progetto)
- [Requisiti](#requisiti)
- [Installazione](#installazione)
- [Utilizzo](#utilizzo)
- [Output generati](#output-generati)
- [Scelte di visualizzazione dei risultati](#scelte-di-visualizzazione-dei-risultati)
- [Limiti e possibili estensioni](#limiti-e-possibili-estensioni)
- [Riferimenti e crediti](#riferimenti-e-crediti)

---

## ğŸ§  Descrizione del progetto

Lâ€™iride Ã¨ uno dei tratti biometrici piÃ¹ affidabili:

- Ã¨ **unica** per ogni individuo (anche nei gemelli monozigoti),
- Ã¨ **stabile nel tempo**,
- Ã¨ **protetta** da cornea e palpebre,
- Ã¨ **difficile da falsificare**.

In questo progetto:

- si lavora su un **dataset di immagini oculari** organizzato per persona,
- si implementa in Python una pipeline completa di **iris recognition**:
  - segmentazione dellâ€™iride,
  - normalizzazione tramite *rubber sheet model*,
  - estrazione di un **IrisCode binario** e relativa maschera,
  - confronto tramite **distanza di Hamming**,
- si analizzano le prestazioni tramite:
  - distanze **genuine** (stessa persona) e **impostor** (persone diverse),
  - **istogrammi bilanciati**,
  - **curva ROC** e **AUC**,
  - un semplice **K-Means** sulle distanze come supporto esplorativo.

---

## âš™ï¸ Algoritmo implementato

Tutto il flusso Ã¨ implementato nello script Python (ad es. `iris_recognition.py`).

### 1. Segmentazione dellâ€™iride

Funzione principale: `segment_iris(img)`

- converte lâ€™immagine in **scala di grigi** e applica un **median blur**;
- usa `cv2.HoughCircles` per rilevare il **cerchio della pupilla**, assumendo:
  - pupilla = regione piÃ¹ scura,
  - parametri scelti per min/max raggio;
- stima il **cerchio dellâ€™iride** come un cerchio piÃ¹ grande, centrato sulla stessa posizione;
- in caso di fallimento di Hough:
  - usa un metodo di emergenza (centro dellâ€™immagine + raggio approssimato);
- output:
  - un cerchio per la **pupilla** `(xp, yp, rp)`
  - un cerchio per il **bordo dellâ€™iride** `(xi, yi, ri)`.

Lâ€™anello tra questi due cerchi Ã¨ la regione ricca di informazione biometrica.

---

### 2. Normalizzazione â€“ Rubber Sheet Model

Funzione: `normalize_iris(img, pupil, iris, radial_res, angular_res)`

Implementa il **rubber sheet model** di Daugman:

- lâ€™anello dellâ€™iride viene â€œsrotolatoâ€ in coordinate polari;
- per ogni angolo `Î¸` e per ogni raggio normalizzato `r âˆˆ [0, 1]`:
  - calcola il punto corrispondente tra bordo pupilla e bordo iride;
  - campiona lâ€™intensitÃ  tramite `ndimage.map_coordinates`;
- il risultato Ã¨ una matrice `radial_res Ã— angular_res` (default: `64 Ã— 256`).

Questa rappresentazione:

- rende le iridi **confrontabili** anche se la pupilla Ã¨ piÃ¹ o meno dilatata,
- porta tutte le immagini nella **stessa dimensione standard**.

---

### 3. Estrazione dellâ€™IrisCode

Funzione: `gabor_filtering(polar, sigma=2.5)`

Step concettuale:

1. Applica un filtro di tipo **Gabor-like** usando:
   - `gaussian_filter` â†’ parte â€œrealeâ€,
   - `gaussian_laplace` â†’ parte â€œimmaginariaâ€ (per la maschera).
2. Soglia la parte reale:
   - se valore > media â†’ bit = 1
   - se valore â‰¤ media â†’ bit = 0
3. Costruisce:
   - `iris_code`: vettore binario (flatten della matrice),
   - `mask`: vettore binario che indica quali bit sono **affidabili** (niente riflessi, ciglia, ecc.).

La maschera viene poi usata per considerare solo i bit â€œvalidiâ€ nel confronto.

---

### 4. Distanza di Hamming e decisione

Funzioni principali:

- `hamming_distance(code1, mask1, code2, mask2)`
- `compute_distances(codes_dict)`
- `compute_roc(genuine, impostor)`
- `compute_auc(fpr, tpr)`

Pipeline:

1. **Calcolo IrisCode per tutte le immagini**  
   Funzione: `compute_all_codes(dataset_path)`  
   Restituisce un dizionario:  
   `persona â†’ lista di (path_immagine, iris_code, mask)`.

2. **Distanze genuine**  
   Per ogni persona:
   - fa tutte le combinazioni a coppie tra le sue immagini,
   - calcola la distanza di Hamming usando solo i bit validi in entrambe le maschere.

3. **Distanze impostor**  
   - prende tutte le coppie tra persone diverse,
   - calcola distanze di Hamming,
   - opzionalmente sottocampiona fino a `MAX_IMPOSTOR_PAIRS` (default: 5000).

4. **Valori attesi**:
   - genuine: distanza tipicamente tra ~0.10 e ~0.35,
   - impostor: distanza attorno a ~0.5 (comportamento casuale).

5. **ROC curve**  
   Varia la soglia `t` da 0 a 1 e per ogni valore calcola:
   - TPR (True Positive Rate) = genuine â‰¤ t
   - FPR (False Positive Rate) = impostor â‰¤ t  
   Da qui:
   - si disegna la **curva ROC**,
   - si calcola lâ€™**AUC** con integrazione numerica.

---

## ğŸ“ Struttura del dataset

Il codice si aspetta un dataset organizzato cosÃ¬:

```text
Eye database/
â”œâ”€â”€ 001/
â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”œâ”€â”€ img2.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ 002/
â”‚   â”œâ”€â”€ img1.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ personA/
â”‚   â”œâ”€â”€ ...
â””â”€â”€ ...matplotlib


pandas



ğŸ“Š Dataset
Il dataset utilizzato Ã¨ composto da oltre 200 immagini di iridi reali, appartenenti sia alla stessa persona che a persone diverse.
La grande variabilitÃ  delle iridi Ã¨ ideale per studiare:
SimilaritÃ  intra-persona


Differenze inter-persona


Andamento delle distanze biometriche



ğŸ” Obiettivi raggiunti
Nel progetto abbiamo:
Processato tutte le immagini del dataset


Generato gli IrisCode


Confrontato tutte le coppie possibili


Calcolato le distanze di Hamming


Prodotto grafici chiari e leggibili per valutare il sistema


Dimostrato che lâ€™algoritmo distingue correttamente iridi genuine e impostor



ğŸ—‚ï¸ File principali
processing.py â€” Estrazione delle feature e IrisCode


analysis.py â€” Calcolo distanze e grafici


dataset/ â€” Immagini dellâ€™iride


results/ â€” Grafici finali e file CSV



ğŸ“Œ Come eseguire il codice
Installare le dipendenze:


pip install -r requirements.txt

Assicurarsi che la cartella dataset/ contenga le immagini.


Eseguire:


python processing.py
python analysis.py


ğŸ“š Autori
Progetto realizzato nellâ€™ambito del corso Principi e Modelli della Percezione.
Team: [Inserisci i nomi del gruppo].

